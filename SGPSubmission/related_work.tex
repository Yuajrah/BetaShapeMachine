\section{Related Work}
\label{sec:related_work}

Our method is related to prior work on data-driven methods for computing shape correspondences in collections with large geometric and structural variability, statistical models of shapes, and deep Boltzmann machines. We review the most relevant work in these areas. A complete review of previous research in shape correspondences and segmentation is out of the scope of this paper. We refer the reader to recent surveys in shape correspondences \cite{vanKaick11},  segmentation \cite{Theologou2015}, and structure-aware shape processing \cite{Mitra13}. 

\textbf{Data-driven shape correspondences.} Analyzing shapes jointly in a collection to extract useful geometric, structural and semantic relationships often yields significantly better results than analyzing isolated single shapes or pairs of shapes, especially for classes of shapes that exhibit large geometric variability. This has been demonstrated in previous data-driven methods for computing point-based and fuzzy correspondences \cite{Kim12,Huang12,Huang13,Huang13b}.  However, these methods do not leverage the part structure of the input shapes and do not learn a model of surface variability. As a result, these methods often do not generalize well to collections of shapes with significant structural diversity. \rev{A number of data-driven methods have been developed to segment shapes and effectively parse their structure \cite{Kalogerakis10,Huang11,Sidi11,Hu12,Wang12,Laga13,Xu2014,Zhige2014}.} However, these methods build correspondences only at a part level, thus cannot be used to find more fine-grained point or region correspondences within parts. Some of these methods require several training labeled segmentations \cite{Kalogerakis10,vanKaick11,Zhige2014} as input, or require users to interactively specify tens to hundreds of constraints \cite{Wang12}. 

Our work is closer to that of Kim et al.~\shortcite{Kim13}. Kim et al. proposed a method that estimates point-level correspondences, part segmentations, rigid shape alignments, and a statistical model of shape variability based on template fitting. The templates are made out of boxes that iteratively fit to segmented parts. Boxes are rather coarse shape representations and in general, shape parts frequently have drastically different geometry than boxes. Our method also makes use of templates to estimate correspondences and segmentations, however, their geometry and deformations are learned from scratch. Our produced templates are neither pre-existing parts nor primitives, but new learned parts equipped with probabilities over their point-based deformations. Kim et al.'s statistical model learns shape variability only in terms of individual box parameters (scale and position) and cannot be used for shape synthesis. In contrast, our statistical model encodes both shape structure and actual surface geometry, thus it can be used to generate shapes. Kim et al.'s method computes hard correspondences via closest points, which are less suitable for typical online shape repositories of inanimate objects. Our method instead infers probabilistic, or fuzzy, correspondences and segmentations via a probabilistic deformation model that combines non-rigid surface alignment, feature-based matching, as well as a deep-learned statistical model of surface geometry and shape structure.  

\textbf{Statistical models of 3D shapes.} Early works developed statistical models of shapes in specific domains, such as faces \cite{Blanz99}, human bodies \cite{Allen03}, and poses \cite{Anguelov05}. Yingze et al.~\shortcite{Yingze13} proposed a statistical model of sparse sets of anchor points by deforming a mean template shape using thin-plate spline (TPS) transformations for shapes, like cars, fruits, and keyboards. Our work can be seen as a generalization of these previous works to domains where shapes differ in both their structure and geometry and where no single template or mean shape can be used. 

A number of approaches have tried to model shape variability using Principal Component Analysis or Gaussian Process Latent Variable models on Signed Distance Function (SDF) representations of shapes \cite{Sandhu11:NKBPE,Chen11:SOPRU,Prisacariu11:SSS,Dame13}. However, the dimensionality of SDF voxel-based representations is very high, requiring the input shapes to be discretized at rather coarse voxel grids or use compression schemes that tend to eliminate surface features of the output shapes. Various ad-hoc weights are frequently used to infer coherent SDF values for the output shapes. \rev{Other methods use deformable templates made out of oriented boxes \cite{Ovsjanikov11,Kim13,Averkiou14}, and model shape variability in terms of the size and position of these boxes. Xu et al. \shortcite{Xu12} mixes-and-matches parts through set evolution with  part mutations (or deformations) following the  box parametrization approach of \cite{Ovsjanikov11} and part crossovers controlled by user-speficied fitness scores. Fish et al.~\shortcite{Fish14} and Yumer et al.~\shortcite{Yumer14} represent shapes in terms of multiple basic primitives (boxes, planes, cylinders etc) and capture shape variability in terms of primitive sizes, relative orientations, and translations. As a result, these methods do not capture statistical variability at the actual surface level and cannot directly be used to generate new surface point arrangements.} Kalogerakis et al.~\shortcite{Kalogerakis12} proposed a generative model of shape structure and part descriptors (e.g., curvature histograms, shape diameter, silhouette features). However, these descriptors are not invertible i.e., they cannot be directly mapped back to surface points. As a result, their model cannot be used to output surface geometry and was only used for shape synthesis by retrieving and recombining database parts without further modifications. \rev{In constrast to the above approaches, our generative model jointly analyzes and synthesizes 3D shape families, outputs both structure and actual surface geometry, as well as learned class-specific shape descriptors.}

\textbf{Deep Boltzmann Machines.} \rev{Our statistical model of surface variability follows the structure of a general class of  generative models, known as Deep Boltzmann Machines (DBMs) in the machine learning literature. DBMs have been used   for speech and image generation \cite{Ranzato11,Roux11,Mohamed12,Salakhutdinov12}, and can also be combined  with discriminative models \cite{Kae2013} for labeling tasks. In a concurrent work, Wu et al. \cite{Wu2015} proposed DBMs built over voxel representations of 3D shapes to produce generic shape descriptors and reconstruct low-resolution shapes from input depth maps.  Our model in inspired by prior work on DBMs to develop a deep generative model of 3D\ shape surfaces. Our model has several differences compared to previous DBM formulations. Our model aims at capturing continuous variability of surfaces instead of pixel or voxel interactions. To  capture surface variability, we use Beta distributions to model surface point locations instead of Gaussian or Bernoulli distributions often used in DBMs. In addition, the connectivity of layers in our model takes into account the structure of shapes based on their parts. Since shape collections have typically a much smaller size than image or audio collections, and since the geometry of surfaces tend to vary smoothly across neighboring points, we use spatial smoothness priors during training. We found that all these adaptations were important to generate surface geometry. }

\vskip -2mm

